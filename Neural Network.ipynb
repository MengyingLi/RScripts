{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align = \"center\"> Neural Network </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Important Terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* transforms a neuron's combined input signals into a single output signal to be broadcasted further in the network (think of package your stuff to a luggage)\n",
    "* Think of the graph as the sum of input signals on the x and the output signal on the y (usually on a 0-1/(-1-1) or (-inf, +inf) scale) \n",
    "* sigmoid activation (logistic sigmoid)/linear/Guassian (Radial Basis Function Network)\n",
    "* Squashing function: hard to differentiate the effect of the input values with a relatively large absolute value. Standardiziong or normalizing is very important so that the features' value will fall within a small range around 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Network topology: the number of neurons and the number of layers and how they are connected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Number of Layers (hidden layers, whether fully connected the nodes in one layer fully connected to all the nodes in another layer) \n",
    "* Whether information in the network is allowed to travel backward (feedforward networks, deep neural network) \n",
    "* The number of nodes within each layer of the network\n",
    "* A neural network with at least one hidden layer of sufficient neurons is a universal function approximator. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Algorithm:  How weights are set in order to inhibit or excite neurons in proportion to the input signal "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Backpropagation:\n",
    "* Each cycle is known as an epoch, the starting weights are typically set at random. Then the algorithm iterates therough the processes, until a stopping criterion is reached. \n",
    "* Each epoch has two phases. 1) forward phase: neurons are activated in sequence from the input layer to the output layer, applying each neuron's weights and activation function along the way 2) Backward phase: the output signal resulting from the forward phase is compared to the true target value in the training data. The difference between the network's output signal and the true value reuslts in an error that is propagated backwards in the network to modify the connection weights between neurons and reduce future errors. (Gradient Descent) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Think it as the first layer produces some smaller models and the output of these models were used for the upper layer. The stack of the models can be represented by a large parameterized numeric functio and the parameters are the coefficients of all the models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Strenghts     | Weakness\n",
    "  ------------- | -------------\n",
    "  1) Can be adapted to classification or numeric prediction problems <br/> 2) capable of modeling more complex patterns  <br/>  3) make few assumptions about the data's underlying relationship| 1) extremely computationally intensive and slow to train <br />  2) Prone to overfitting the data  <br/>3) Difficult to explain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### Chapter 7: Neural Networks and Support Vector Machines -------------------\n",
    "\n",
    "##### Part 1: Neural Networks -------------------\n",
    "## Example: Modeling the Strength of Concrete  ----\n",
    "\n",
    "## Step 2: Exploring and preparing the data ----\n",
    "# read in data and examine structure\\\n",
    "setwd(\"E:/Personal/InterviewQuestion/Rscripts/Machine Learning with R, Second Edition_Code/Chapter 07\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t1030 obs. of  9 variables:\n",
      " $ cement      : num  141 169 250 266 155 ...\n",
      " $ slag        : num  212 42.2 0 114 183.4 ...\n",
      " $ ash         : num  0 124.3 95.7 0 0 ...\n",
      " $ water       : num  204 158 187 228 193 ...\n",
      " $ superplastic: num  0 10.8 5.5 0 9.1 0 0 6.4 0 9 ...\n",
      " $ coarseagg   : num  972 1081 957 932 1047 ...\n",
      " $ fineagg     : num  748 796 861 670 697 ...\n",
      " $ age         : int  28 14 28 28 28 90 7 56 28 28 ...\n",
      " $ strength    : num  29.9 23.5 29.2 45.9 18.3 ...\n"
     ]
    }
   ],
   "source": [
    "concrete <- read.csv(\"concrete.csv\")\n",
    "str(concrete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n",
       " 0.0000  0.2664  0.4001  0.4172  0.5457  1.0000 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# custom normalization function\n",
    "normalize <- function(x) { \n",
    "  return((x - min(x)) / (max(x) - min(x)))\n",
    "}\n",
    "\n",
    "# apply normalization to entire data frame\n",
    "concrete_norm <- as.data.frame(lapply(concrete, normalize))\n",
    "\n",
    "# confirm that the range is now between zero and one\n",
    "summary(concrete_norm$strength) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n",
       "   2.33   23.71   34.44   35.82   46.14   82.60 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compared to the original minimum and maximum\n",
    "summary(concrete$strength)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any transformation applied to the data prior to training the model will have to be applied in reverse later on, in order to convert back to the original units of measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create training and test data\n",
    "concrete_train <- concrete_norm[1:773, ]\n",
    "concrete_test <- concrete_norm[774:1030, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: grid\n",
      "Loading required package: MASS\n"
     ]
    }
   ],
   "source": [
    "## Step 3: Training a model on the data ----\n",
    "# train the neuralnet model\n",
    "library(neuralnet) #we can use nnet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# simple ANN with only a single hidden neuron\n",
    "set.seed(12345) # to guarantee repeatable results\n",
    "concrete_model <- neuralnet(formula = strength ~ cement + slag +\n",
    "                              ash + water + superplastic + \n",
    "                              coarseagg + fineagg + age,\n",
    "                              data = concrete_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A neural network with a single hidden node can be thought of as a distant cousion of the linear regression models. The weight between each input node and the hidden node is similar to the regression coefficients, and the weight for the bias term is similar to the intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev.new(): using pdf(file=\"Rplots10.pdf\")\n"
     ]
    }
   ],
   "source": [
    "# visualize the network topology\n",
    "plot(concrete_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>0.806465557619181</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{l}\n",
       "\t 0.806465557619181\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "0.806465557619181"
      ],
      "text/plain": [
       "             [,1]\n",
       "[1,] 0.8064655576"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Step 4: Evaluating model performance ----\n",
    "# obtain model results\n",
    "model_results <- compute(concrete_model, concrete_test[1:8])\n",
    "# obtain predicted strength values\n",
    "predicted_strength <- model_results$net.result\n",
    "# examine the correlation between predicted and actual values\n",
    "cor(predicted_strength, concrete_test$strength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dev.new(): using pdf(file=\"Rplots8.pdf\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>0.92445334258464</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{l}\n",
       "\t 0.92445334258464\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "0.92445334258464"
      ],
      "text/plain": [
       "             [,1]\n",
       "[1,] 0.9244533426"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Step 5: Improving model performance ----\n",
    "# a more complex neural network topology with 5 hidden neurons\n",
    "set.seed(12345) # to guarantee repeatable results\n",
    "concrete_model2 <- neuralnet(strength ~ cement + slag +\n",
    "                               ash + water + superplastic + \n",
    "                               coarseagg + fineagg + age,\n",
    "                               data = concrete_train, hidden = 5)\n",
    "\n",
    "# plot the network\n",
    "plot(concrete_model2)\n",
    "\n",
    "# evaluate the results as we did before\n",
    "model_results2 <- compute(concrete_model2, concrete_test[1:8])\n",
    "predicted_strength2 <- model_results2$net.result\n",
    "cor(predicted_strength2, concrete_test$strength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>pdf:</strong> 3"
      ],
      "text/latex": [
       "\\textbf{pdf:} 3"
      ],
      "text/markdown": [
       "**pdf:** 3"
      ],
      "text/plain": [
       "pdf \n",
       "  3 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dev.off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>pdf:</strong> 3"
      ],
      "text/latex": [
       "\\textbf{pdf:} 3"
      ],
      "text/markdown": [
       "**pdf:** 3"
      ],
      "text/plain": [
       "pdf \n",
       "  3 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dev.off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* training algorithm:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
